{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "prosodic_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsusiep/slp2019/blob/master/prosodic_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "01QQprgqlCqx"
      },
      "source": [
        "This notebook trains a Tacotron + Prosodic Embeddings model, using the LJSpeech1.1 dataset.\n",
        "\n",
        "Make sure that you have added a folder with the contents of https://github.com/syang1993/gst-tacotron/ to your Drive's root folder. This notebook assumes you have already downloaded the LJ Speech dataset and run preprocess.py, and are ready to train a model. \n",
        "\n",
        "Also, the checkpoint frequency in train.py has been changed from every 2 hours, to 30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iG3KnBpJkVBS",
        "outputId": "9e4246d9-e364-4587-f4a9-f65419564dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6RXqmUBCZ3_J",
        "outputId": "12c2b69d-4817-4702-d8a1-6a7a9feca554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd 'gdrive/My Drive/gst-tacotron'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/gst-tacotron\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tb0chxGiP6bi",
        "outputId": "20924303-6154-4632-91cc-d5a93a7f71ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "!pip install tensorflow==1.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9f/be0165c6eefd841e6928e54d3d083fa174f92d640fdc52f73a33dc9c54d1/tensorflow-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (41.2MB)\n",
            "\u001b[K     |████████████████████████████████| 41.2MB 212kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (3.10.0)\n",
            "Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/9f/5845c18f9df5e7ea638ecf3a272238f0e7671e454faa396b5188c6e6fc0a/tensorflow_tensorboard-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (1.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4) (1.12.0)\n",
            "Collecting enum34>=1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (3.1.1)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 69.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (0.16.0)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107221 sha256=828d61fd2946658391bcf302c1303fb4960c81c5aa6737f0293cf19fbceb4622\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html5lib, bleach, tensorflow-tensorboard, enum34, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Qcc1qylRNM6",
        "outputId": "4d6e9767-005d-4bc6-dcb2-744848566953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting falcon==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/4b/0c2592c5af5d106aafb653c84cc796665fdf4e3dfd2e6e566abbfaa2c50c/falcon-1.2.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.9MB/s \n",
            "\u001b[?25hCollecting inflect==0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/15/2d176749884cbeda0c92e0d09e1303ff53a973eb3c6bb2136803b9d962c9/inflect-0.2.5-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hCollecting librosa==0.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/c2/d8d8498252a2430ec9b90481754aca287c0ecc237a8feb331fa3b8933575/librosa-0.5.1.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 72.6MB/s \n",
            "\u001b[?25hCollecting matplotlib==2.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/d4/6b6d8a7a6bc69a1602ab372f6fc6e88ef88a8a96398a1a25edbac636295b/matplotlib-2.0.2-cp36-cp36m-manylinux1_x86_64.whl (14.6MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6MB 49.7MB/s \n",
            "\u001b[?25hCollecting numpy==1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ce/70cbaf09bdba60b624bb609fa53f7c4e2a0ea4b3c24132e934274d596121/numpy-1.13.0-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0MB 306kB/s \n",
            "\u001b[?25hCollecting scipy==0.19.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/7b/415fd5bb215f28b423d32dc98126f700ebe7f1efa53e65377ed6ed55df99/scipy-0.19.0-cp36-cp36m-manylinux1_x86_64.whl (48.2MB)\n",
            "\u001b[K     |████████████████████████████████| 48.2MB 183kB/s \n",
            "\u001b[?25hCollecting tqdm==4.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/0d/174388e99e21ee2c91ea318994c3f8744e26158e43cff0ec9d045bf08a96/tqdm-4.11.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hCollecting Unidecode==0.4.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/6f/05f5deb753d0594583aa1cc0d2fe9d631d9a00e9b28d0da49f8d3763755b/Unidecode-0.04.20-py2.py3-none-any.whl (228kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 65.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from falcon==1.2.0->-r requirements.txt (line 3)) (1.12.0)\n",
            "Collecting python-mimeparse>=1.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2e/03bce213a9bf02a2750dcb04e761785e9c763fc11071edc4b447eacbb842/python_mimeparse-1.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 5)) (2.1.8)\n",
            "Requirement already satisfied: scikit-learn>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 5)) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 5)) (4.4.1)\n",
            "Requirement already satisfied: resampy>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.5.1->-r requirements.txt (line 5)) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 6)) (2.4.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.2->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy>=0.1.2->librosa==0.5.1->-r requirements.txt (line 5)) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy>=0.1.2->librosa==0.5.1->-r requirements.txt (line 5)) (0.30.0)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.5.1-cp36-none-any.whl size=1547565 sha256=18a99bdb1e2afb76e418e69e0c05f7af04e13da3901d9f0b05c736edfa0a6cd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/21/55/9c17b30d30ef57e74b50c8824c2bb368d58ddabf9bf8e1fee0\n",
            "Successfully built librosa\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.1.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pywavelets 1.1.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 0.14.1 has requirement numpy>=1.14, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.5.1 has requirement matplotlib>=3.0.0, but you'll have matplotlib 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.5.1 has requirement scipy>=1.0.0, but you'll have scipy 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 0.25.3 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mir-eval 0.5 has requirement scipy>=1.0.0, but you'll have scipy 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement librosa>=0.6.2, but you'll have librosa 0.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement tqdm>=4.19.2, but you'll have tqdm 4.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.59 has requirement numpy>=1.15, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement numpy>=1.15, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement scipy>=1.1.0, but you'll have scipy 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: python-mimeparse, falcon, inflect, numpy, scipy, librosa, matplotlib, tqdm, Unidecode\n",
            "  Found existing installation: inflect 2.1.0\n",
            "    Uninstalling inflect-2.1.0:\n",
            "      Successfully uninstalled inflect-2.1.0\n",
            "  Found existing installation: numpy 1.17.3\n",
            "    Uninstalling numpy-1.17.3:\n",
            "      Successfully uninstalled numpy-1.17.3\n",
            "  Found existing installation: scipy 1.3.1\n",
            "    Uninstalling scipy-1.3.1:\n",
            "      Successfully uninstalled scipy-1.3.1\n",
            "  Found existing installation: librosa 0.6.3\n",
            "    Uninstalling librosa-0.6.3:\n",
            "      Successfully uninstalled librosa-0.6.3\n",
            "  Found existing installation: matplotlib 3.1.1\n",
            "    Uninstalling matplotlib-3.1.1:\n",
            "      Successfully uninstalled matplotlib-3.1.1\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed Unidecode-0.4.20 falcon-1.2.0 inflect-0.2.5 librosa-0.5.1 matplotlib-2.0.2 numpy-1.13.0 python-mimeparse-1.6.0 scipy-0.19.0 tqdm-4.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6veQprJraJNB",
        "outputId": "79ccc379-0ef1-47ca-bf9a-0cbe980a77ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# !python3 preprocess.py --dataset ljspeech --num_workers 4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
            "  return f(*args, **kwds)\n",
            "100% 13100/13100 [1:19:36<00:00,  3.28it/s]\n",
            "Wrote 13100 utterances, 6895992 frames (23.94 hours)\n",
            "Max input length:  187\n",
            "Max output length: 808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "at4MDT4uRzP7",
        "outputId": "5b62bc48-539e-4c1b-b0fd-3381df8f57bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 train.py --hparams=\"use_gst=False\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
            "  return f(*args, **kwds)\n",
            "Checkpoint path: /content/gdrive/My Drive/gst-tacotron/logs-tacotron/model.ckpt\n",
            "Loading training data from: /content/gdrive/My Drive/gst-tacotron/training/train.txt\n",
            "Using model: tacotron\n",
            "Hyperparameters:\n",
            "  adam_beta1: 0.9\n",
            "  adam_beta2: 0.999\n",
            "  attention_depth: 256\n",
            "  batch_size: 32\n",
            "  cleaners: english_cleaners\n",
            "  decay_learning_rate: True\n",
            "  embed_depth: 256\n",
            "  encoder_depth: 256\n",
            "  frame_length_ms: 50\n",
            "  frame_shift_ms: 12.5\n",
            "  griffin_lim_iters: 60\n",
            "  initial_learning_rate: 0.002\n",
            "  max_iters: 1000\n",
            "  min_level_db: -100\n",
            "  num_freq: 1025\n",
            "  num_gst: 10\n",
            "  num_heads: 4\n",
            "  num_mels: 80\n",
            "  outputs_per_step: 2\n",
            "  power: 1.5\n",
            "  preemphasis: 0.97\n",
            "  prenet_depths: [256, 128]\n",
            "  ref_level_db: 20\n",
            "  reference_depth: 128\n",
            "  reference_filters: [32, 32, 64, 64, 128, 128]\n",
            "  rnn_depth: 256\n",
            "  sample_rate: 16000\n",
            "  style_att_dim: 128\n",
            "  style_att_type: mlp_attention\n",
            "  style_embed_depth: 256\n",
            "  use_cmudict: False\n",
            "  use_gst: False\n",
            "Loaded metadata for 13100 examples (23.94 hours)\n",
            "Initialized Tacotron model. Dimensions: \n",
            "  text embedding:          256\n",
            "  style embedding:         128\n",
            "  prenet out:              128\n",
            "  encoder out:             384\n",
            "  attention out:           256\n",
            "  concat attn & out:       640\n",
            "  decoder cell out:        256\n",
            "  decoder out (2 frames):  160\n",
            "  decoder out (1 frame):   80\n",
            "  postnet out:             256\n",
            "  linear out:              1025\n",
            "Starting new training run at commit: None\n",
            "Generated 32 batches of size 32 in 20.506 sec\n",
            "Step 1       [68.738 sec/step, loss=0.92913, avg_loss=0.92913]\n",
            "Step 2       [54.699 sec/step, loss=0.93316, avg_loss=0.93115]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g2_LAkp1atQz",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}