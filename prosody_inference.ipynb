{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prosody_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsusiep/slp2019/blob/master/prosody_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrBgg6tNz_IW",
        "colab_type": "text"
      },
      "source": [
        "This notebook loads a model that generates prosody embeddings (using the Tacotron architecture). Original model code from https://github.com/syang1993/gst-tacotron/. \n",
        "\n",
        "This notebook expects that you already have run the preprocess_utterances notebook, generating a folder with mel spectrograms from individual utterances, which have been pulled from audio files that have had music removed. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzgDHwJezvd9",
        "colab_type": "code",
        "outputId": "112d7f1f-5637-4515-909e-7ee439b6157e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import tensorflow as tf\n",
        "!git clone https://github.com/syang1993/gst-tacotron.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Cloning into 'gst-tacotron'...\n",
            "remote: Enumerating objects: 375, done.\u001b[K\n",
            "remote: Total 375 (delta 0), reused 0 (delta 0), pack-reused 375\u001b[K\n",
            "Receiving objects: 100% (375/375), 421.74 KiB | 763.00 KiB/s, done.\n",
            "Resolving deltas: 100% (244/244), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQHJqkWEFEZG",
        "colab_type": "code",
        "outputId": "e462a1d2-6ae0-4ae3-d96d-7aa5b0d747a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd gst-tacotron"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gst-tacotron/gst-tacotron/gst-tacotron\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctAJBSjXFKYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFDc_itSH1Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = tf.contrib.training.HParams(\n",
        "  # Comma-separated list of cleaners to run on text prior to training and eval. For non-English\n",
        "  # text, you may want to use \"basic_cleaners\" or \"transliteration_cleaners\" See TRAINING_DATA.md.\n",
        "  cleaners='english_cleaners',\n",
        "\n",
        "  # Audio:\n",
        "  num_mels=80,\n",
        "  num_freq=1025,\n",
        "  sample_rate=16000,\n",
        "  frame_length_ms=50,\n",
        "  frame_shift_ms=12.5,\n",
        "  preemphasis=0.97,\n",
        "  min_level_db=-100,\n",
        "  ref_level_db=20,\n",
        "\n",
        "  # Model:\n",
        "  outputs_per_step=2,\n",
        "  embed_depth=256,\n",
        "  prenet_depths=[256, 128],\n",
        "  encoder_depth=256,\n",
        "  rnn_depth=256,\n",
        "\n",
        "  # Attention\n",
        "  attention_depth=256,\n",
        "\n",
        "\n",
        "  # Training:\n",
        "  batch_size=32,\n",
        "  adam_beta1=0.9,\n",
        "  adam_beta2=0.999,\n",
        "  initial_learning_rate=0.002,\n",
        "  decay_learning_rate=True,\n",
        "  use_cmudict=False,  # Use CMUDict during training to learn pronunciation of ARPAbet phonemes\n",
        "\n",
        "  # Eval:\n",
        "  max_iters=1000,\n",
        "  griffin_lim_iters=60,\n",
        "  power=1.5,              # Power to raise magnitudes to prior to Griffin-Lim\n",
        "\n",
        "  #Global style token\n",
        "  use_gst=False,     # When false, the scripit will do as the paper  \"Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron\"\n",
        "  num_gst=10,\n",
        "  num_heads=4,       # Head number for multi-head attention\n",
        "  style_embed_depth=256,\n",
        "  reference_filters=[32, 32, 64, 64, 128, 128],\n",
        "  reference_depth=128,\n",
        "  style_att_type=\"mlp_attention\", # Attention type for style attention module (dot_attention, mlp_attention)\n",
        "  style_att_dim=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-KQnmjx7a4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from models import create_model\n",
        "from text import text_to_sequence\n",
        "from util import audio, plot\n",
        "import textwrap\n",
        "\n",
        "\n",
        "class Synthesizer:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def load(self, reference_mel=None, model_name='tacotron'):\n",
        "    print('Constructing model: %s' % model_name)\n",
        "    inputs = tf.placeholder(tf.int32, [1, None], 'inputs')\n",
        "    input_lengths = tf.placeholder(tf.int32, [1], 'input_lengths') \n",
        "    if reference_mel is not None:\n",
        "      reference_mel = tf.placeholder(tf.float32, [1, None, hparams.num_mels], 'reference_mel')\n",
        "\n",
        "    with tf.variable_scope('model') as scope:\n",
        "      self.model = create_model(model_name, hparams)\n",
        "      self.model.initialize(inputs, input_lengths, mel_targets=None, reference_mel=reference_mel)\n",
        "      self.wav_output = audio.inv_spectrogram_tensorflow(self.model.linear_outputs[0])\n",
        "      self.alignments = self.model.alignments[0]\n",
        "\n",
        "    print('Loading checkpoint')\n",
        "    self.session = tf.Session()\n",
        "    self.session.run(tf.global_variables_initializer())\n",
        "    # saver = tf.train.import_meta_graph('/content/gdrive/My Drive/prosody_model/model.ckpt-50000.meta')\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(self.session, \"/content/gdrive/My Drive/prosody_model/model.ckpt-50000\")\n",
        "\n",
        "  def synthesize(self, text, reference_path=None):\n",
        "    cleaner_names = [x.strip() for x in hparams.cleaners.split(',')]\n",
        "    seq = text_to_sequence(text, cleaner_names)\n",
        "    feed_dict = {\n",
        "      self.model.inputs: [np.asarray(seq, dtype=np.int32)],\n",
        "      self.model.input_lengths: np.asarray([len(seq)], dtype=np.int32),\n",
        "    }\n",
        "    if reference_path is not None:\n",
        "      reference_mel = np.load(reference_path)\n",
        "      reference_mel = np.expand_dims(reference_mel, 0)\n",
        "      feed_dict.update({self.model.reference_mel: np.asarray(reference_mel, dtype=np.float32)})\n",
        "\n",
        "    # we only want to get the embeddings out, so we explicitly ask just for those\n",
        "    op_to_restore = self.session.graph.get_tensor_by_name(\"model/inference/ref_encoder/dense/Tanh:0\")\n",
        "\n",
        "    embeddings = self.session.run(op_to_restore, feed_dict=feed_dict)\n",
        "    return(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPYm2qYPUgqy",
        "colab_type": "code",
        "outputId": "e3689116-2227-4d13-f09c-6c7d63c46138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "synth = Synthesizer()\n",
        "synth.load(reference_mel=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Constructing model: tacotron\n",
            "Initialized Tacotron model. Dimensions: \n",
            "  text embedding:          256\n",
            "  style embedding:         128\n",
            "  prenet out:              128\n",
            "  encoder out:             384\n",
            "  attention out:           256\n",
            "  concat attn & out:       640\n",
            "  decoder cell out:        256\n",
            "  decoder out (2 frames):  160\n",
            "  decoder out (1 frame):   80\n",
            "  postnet out:             256\n",
            "  linear out:              1025\n",
            "Loading checkpoint\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/prosody_model/model.ckpt-50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjq26mhUFmO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset in case we rerun this cell\n",
        "# tf.reset_default_graph()\n",
        "\n",
        "# check for existing files\n",
        "import time\n",
        "import glob \n",
        "import os\n",
        "existing_files = glob.glob('/content/gdrive/My Drive/preprocessed_prosody_model_inputs/*.npy')\n",
        "\n",
        "# run inference to get embeddings, only on new files\n",
        "for f in existing_files:\n",
        "  yt_link = f.split('preprocessed_prosody_model_inputs/')[1].split('-mel.npy')[0]\n",
        "  if not any(yt_link in x for x in os.listdir('/content/gdrive/My Drive/prosody_embeddings/')):\n",
        "    embeddings = synth.synthesize('dummy text', reference_path='/content/gdrive/My Drive/preprocessed_prosody_model_inputs/' + yt_link + '-mel.npy')\n",
        "    np.save('/content/gdrive/My Drive/prosody_embeddings/' + yt_link, embeddings, allow_pickle=True)\n",
        "    time.sleep(0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}